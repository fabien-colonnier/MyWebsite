.. title: Research
.. slug: research
.. date: 2019-05-03 15:13:00 UTC+08:00
.. tags: 
.. category: 
.. link: 
.. description: 
.. type: text



My research interest is mainly focused on visual navigation for robotic application. I use bio-inspired method to solve robotic tasks such as stabilization, pursuit and obstacle avoidance.

<h2> Event-based visual sensor </h2>

A nice description of how the sensor works can be found <a href="https://youtu.be/LauQ6LWTkxM" target="_blank"> here </a> <br />

<ul>
<li>
<p>A relatively simple event to 3D point matching was used as input measurement of an EKF to perform sensor pose estimation. The algorithm was also adapted for multiple sensors and with mapping it shows good accuracy on the tested environment.<br /> </p>

<table style="width:100%; text-align: center;">
	<tr>
	   <th style="text-align:center;"> <iframe width="448" height="252" src="https://www.youtube.com/embed/m2R94LlqpEM" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> </th>
	   <th style="text-align:center;"> <iframe width="448" height="252" src="https://www.youtube.com/embed/2u4s0GUAWMI" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> </th>
	</tr>
</table>
</li>

<li>
<p>The Davis240C sensor was used to compute Optic Flow and perform obstacle avoidance with a quadrotor. <br /> </p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/nn2wyDYJI8c" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="true"></iframe>
<!--video width="560" height="315" controls preload="none" frameborder="0">
   <source src="https://linklings.s3.amazonaws.com/organizations/acra/acra2018/submissions/stype101/UGjfY-pap104s1-file2.mp4" type="video/mp4">
   Your browser does not support the video tag.
</video-->

</li>
</ul>

<!--<a href="https://linklings.s3.amazonaws.com/organizations/acra/acra2018/submissions/stype101/UGjfY-pap104s1-file2.mp4"> video</a> -->


<h2> Insect inspired vision and application </h2>

The following research was made during my PhD in the Biorobotics team in Marseille. My thesis can be downloaded here: <a href="/files/These_COLONNIER_Fabien.pdf"> Link to thesis</a> .

<ul>
<li>
Using an Artificial compound eye submitted to periodic micro-movements displays hyperacuity, <i>i.e.</i> locating features with a greater accuracy than that corresponding to the resolution imposed by the photoreceptorâ€™s limited pitch. Application of this principal over a large field of view allowed a robot to stabilized is position or follow a target.<br />
	<ul>
	<li>
	<p>Robotic visual stabilization and short-range odometry</p>
	<iframe width="560" height="315" src="https://www.youtube.com/embed/4_hqCgunhNw" frameborder="0" allow="accelerometer; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="true"></iframe>
	</li>
	<li>
	<p>Robotic visual pursuit under different light conditions </p>
	<iframe width="560" height="315" src="https://www.youtube.com/embed/kdjJ6t7d2pM" frameborder="0" allow="accelerometer;  encrypted-media; gyroscope; picture-in-picture" allowfullscreen="true"></iframe>
	<p> <br />which mimics the behavior of hoverfly trajectories</p>
	<iframe width="560" height="315" src="https://www.youtube.com/embed/fciQr0o0G7g" frameborder="0" allow="accelerometer;  encrypted-media; gyroscope; picture-in-picture" allowfullscreen="true"></iframe>
	</li>
	</ul>
</li>
<br />

<li> <p>Collaboration on the robot LORA, which aims at replicating bees navigation into a large corridor. The different behaviors such as centering, wall-following and speed regulation in a tappered corridor were reproduced using Optic Flow measurements. <br /> </p>

<iframe frameborder="0" width="560" height="315" src="https://www.dailymotion.com/embed/video/xuggrs" allowfullscreen="true" allow=""></iframe>
</li>

</ul>






